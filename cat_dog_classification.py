# -*- coding: utf-8 -*-
"""cat_dog_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/azrielrisywan/team-assignment-2-ai-binus/blob/master/cat_dog_classification.ipynb

# **Table of Contents**

1. Introduction
1. Import library
1. Fetch datasets from kaggle
1. Prepare training data
1. Data pre-processing
1. Model building
1. Prepare testing data
1. Find prediction

# **Introduction**

In this project, we'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats but our computer will find it a bit more difficult.
### Data Description
The folder "train" contains two sub-folders "cats" & "dogs" which contain images of cats and dogs respectively.The folder "test1" contain unknown images which we have to classify.
### Data
To download the Dataset click [here](https://www.kaggle.com/c/dogs-vs-cats/data)
### Objective
To build a deep learning classification model which classify whether images contain either a dog or a cat.

# Tambah dependency untuk hyperparameter tuning
"""

!pip install keras-tuner

!pip install kaggle

"""# **1. Import Library**"""

import numpy as np
import pandas as pd
import tensorflow as tf
import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img  # Perbarui impor
from tensorflow.keras.utils import to_categorical  # Perbarui impor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import random
import os

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import keras_tuner as kt  # Untuk hyperparameter tuning

"""# **2. Fetch datasets from kaggle**"""

# Step-1: create .kaggle directory
!mkdir ~/.kaggle

# Step-2: create a API token in your kaggle account.Upload this token("kaggle.json") on any folder here.move this file into ~/.kaggle.
# Below code is for moving ".json" file
!mv /content/sample_data/kaggle.json ~/.kaggle/kaggle.json

# Step-3: give authorization to KaggleApi
from kaggle.api.kaggle_api_extended import KaggleApi
api = KaggleApi()
api.authenticate()

!chmod 600 ~/.kaggle/kaggle.json

# Step-4: Download datasets from kaggle using API
!kaggle competitions download -c dogs-vs-cats

# unzip the dataset
from zipfile import ZipFile
zf = ZipFile('/content/sample_data/train/train.zip')
zf.extractall('/content/sample_data/train') #save files in selected folder
zf.close()

"""# **3. Prepare Training Data**
Here we will create dataframe which will store all file names in "filenames" column and value "1" for "dog" and "0" for "cat".
"""

filenames = os.listdir("/content/sample_data/train/train")
categories = []
for name in filenames:
    category = name.split('.')[0]
    if category == 'dog':
        categories.append(1)
    else:
        categories.append(0)

image_df = pd.DataFrame({
    'filename': filenames,
    'category': categories
})

# See top 5 rows of the dataset
image_df.head()

# See buttom 5 cell of the dataset
image_df.tail()

image_df.shape

# visualize number of cats and dogs present in the dataframe
image_df['category'].value_counts().plot.bar()

"""## **3.1. Sample Image**"""

sample = random.choice(filenames)
image = load_img("/content/sample_data/train/train/"+sample)
plt.imshow(image)

"""# **4.Data Pre-processing**
As we use image genaretor `with class_mode="categorical"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding.

So we will convert 1 to "dog" and 0 to "cat"
"""

# replace 0 as "cat" & 1 as "dog"
image_df["category"] = image_df["category"].replace({0: 'cat', 1: 'dog'})

# split the dataset for training & testing
train_df, validate_df = train_test_split(image_df, test_size=0.20, random_state=23)
# training dataset
train_df = train_df.reset_index(drop=True)
# testing dataset
validate_df = validate_df.reset_index(drop=True)

# see frequency of class variables in target column of training dataset
train_df['category'].value_counts().plot.bar(color=["cyan","pink"])

# see frequency of class variables in target column of testing dataset
validate_df['category'].value_counts().plot.bar(color=["cyan","pink"])

"""## **4.1. Define Constants**"""

FAST_RUN = False
IMAGE_WIDTH=128
IMAGE_HEIGHT=128
IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)
IMAGE_CHANNELS=3
batch_size=4

train_df_size = train_df.shape[0]
validate_df_size = validate_df.shape[0]

"""## **4.2. Training Generator**"""

train_datagen = ImageDataGenerator(
    rotation_range=15,
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)

train_generator = train_datagen.flow_from_dataframe(
    train_df,
    "/content/sample_data/train/train/",
    x_col='filename',
    y_col='category',
    target_size=IMAGE_SIZE,
    class_mode='categorical',
    batch_size=batch_size
)

"""## **4.3. Validation Generator**"""

validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_dataframe(
    validate_df,
    "/content/sample_data/train/train",
    x_col='filename',
    y_col='category',
    target_size=IMAGE_SIZE,
    class_mode='categorical',
    batch_size=batch_size
)

"""## **4.4. See how generator work**"""

example_df = train_df.sample(n=1).reset_index(drop=True)
example_generator = train_datagen.flow_from_dataframe(
    example_df,
    "/content/sample_data/train/train/",
    x_col='filename',
    y_col='category',
    target_size=IMAGE_SIZE,
    class_mode='categorical'
)

# visualize generated images from one image
plt.figure(figsize=(12, 12))
for i in range(0, 15):
    plt.subplot(5, 3, i+1)
    for X_batch, Y_batch in example_generator:
        image = X_batch[0]
        plt.imshow(image)
        break
plt.tight_layout()
plt.show()

"""# **5. Model Building**
<img src="https://media.geeksforgeeks.org/wp-content/uploads/cat-vs-dog.jpg" width="100%"/>

* **Conv Layer**: Convolutional layers are the layers where filters are applied to the original image, or to other feature maps in a deep CNN.
* **Conv2D Layer**: Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.
* **Pooling Layer**: Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network.
* **Fully Connected Layer**: It connect the network from a layer to another layer
* **Output Layer**: It is the predicted values layer.
* **BatchNormalization**: Layer that normalizes its inputs.Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.

* Pakai **Transfer Learning** untuk membuat training model lebih efektif dan menghasilkan model yang lebih baik
"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D

def build_model(hp):
    base_model = MobileNetV2(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),
                             include_top=False, weights='imagenet')
    base_model.trainable = False  # Bekukan bobot pre-trained

    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(hp.Int('units', 128, 512, step=128), activation='relu'),
        Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1)),
        Dense(2, activation='softmax')
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(
            hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')
        ),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Inisialisasi tuner
tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',  # Optimalkan berdasarkan akurasi validasi
    max_trials=3,  # Coba 10 kombinasi hyperparameter
    executions_per_trial=1,
    directory='tuner_dir',
    project_name='cat_dog_tuning'
)

# Tampilkan ringkasan pencarian
tuner.search_space_summary()

"""## **5.1. Callback Functions**
A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.
- **EarlyStopping** : Used to avoid overfitting.Here we'll stop the training if there is no improvement in 3 conjecutive epochs.
- **ModelCheckpoint** : This callback saves the model after every epoch.The model'll save in a particular location with minimun 'val_loss'.
- **ReduceLROnPlateau** : It reduces learning rate when a metric has stopped improving.
For more about callback function click [here](https://www.kdnuggets.com/2019/08/keras-callbacks-explained-three-minutes.html) [here](https://keras.io/api/callbacks/)
"""

# EarlyStopping
earlystop = EarlyStopping(monitor = 'val_loss',
                          min_delta = 0,
                          patience = 7,
                          verbose = 1,
                          restore_best_weights = True)

# ModelCheckPoint
checkPoint = keras.callbacks.ModelCheckpoint(filepath="/content/sample_data/cd_model.h5",
                             monitor='val_loss',
                             mode='min',
                             save_best_only=True,
                             verbose=1)

# ReduceLROnPlateau
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',
                                            patience=2,
                                            verbose=1,
                                            factor=0.5,
                                            min_lr=0.00001)

# TBoard = tf.keras.callbacks.TensorBoard(log_dir='./logs')

callbacks = [earlystop , checkPoint, learning_rate_reduction]

# this code is to show how much time required to train the model using different algorithms
from datetime import datetime
def timer(start_time= None):
  if not start_time:
    start_time=datetime.now()
    return start_time
  elif start_time:
    thour,temp_sec=divmod((datetime.now()-start_time).total_seconds(),3600)
    tmin,tsec=divmod(temp_sec,60)
    print('\n Time taken: %i hours %i minutes and %s seconds. '% (thour,tmin,round(tsec,2)))

"""## **5.2. Model Fitting**"""

start_time = timer(None)
tuner.search(
    train_generator,
    epochs=3 if FAST_RUN else 5,  # Kurangi epoch untuk testing cepat, idealnya 20-40
    validation_data=validation_generator,
    validation_steps=validate_df_size//batch_size,
    steps_per_epoch=train_df_size//batch_size,
    callbacks=callbacks
)
timer(start_time)

"""## **5.3. Save the Model**"""

# Ambil model terbaik
best_model = tuner.get_best_models(num_models=1)[0]

# Tampilkan ringkasan model terbaik
best_model.summary()

# Simpan model terbaik
best_model.save("cat_dog_classifier_tuned.h5")

"""## **5.4. Load Model**"""

from keras.models import load_model
new_model = load_model('/content/cat_dog_classifier_tuned.h5')

"""## **5.5. Visualize training accuracy and loss**"""

# Latih ulang model terbaik untuk mendapatkan history (opsional)
history = best_model.fit(
    train_generator,
    epochs=3 if FAST_RUN else 5,
    validation_data=validation_generator,
    validation_steps=validate_df_size//batch_size,
    steps_per_epoch=train_df_size//batch_size,
    callbacks=callbacks
)

# Visualisasi
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))

# Plot training & validation loss
ax1.plot(history.history['loss'], color='b', label="Training loss")
ax1.plot(history.history['val_loss'], color='r', label="Validation loss")
ax1.set_xlabel("Epochs")
ax1.set_ylabel("Loss")
ax1.set_title("Training and Validation Loss")
ax1.legend()

# Plot training & validation accuracy
ax2.plot(history.history['accuracy'], color='b', label="Training accuracy")
ax2.plot(history.history['val_accuracy'], color='r', label="Validation accuracy")
ax2.set_xlabel("Epochs")
ax2.set_ylabel("Accuracy")
ax2.set_title("Training and Validation Accuracy")
ax2.legend()

plt.tight_layout()
plt.savefig('accuracy_loss_tuned.png')
plt.show()

from google.colab import drive
drive.mount('/content/drive')

"""# **6. Prepare Testing Data**"""

# unzip the dataset
from zipfile import ZipFile
zf = ZipFile('/content/sample_data/train/test1.zip')
zf.extractall('/content/sample_data') #save files in selected folder
zf.close()

# create a dataframe and store all image files
test_filenames = os.listdir("/content/sample_data/test1")
test_df = pd.DataFrame({
    'filename': test_filenames
})
nb_samples = test_df.shape[0]

"""## **6.1. Create Testing Generator**"""

test_gen = ImageDataGenerator(rescale=1./255)
test_generator = test_gen.flow_from_dataframe(
    test_df,
    "/content/sample_data/test1/",
    x_col='filename',
    y_col=None,
    class_mode=None,
    target_size=IMAGE_SIZE,
    batch_size=batch_size,
    shuffle=False
)

"""# **7. Find Prediction**"""

# Hitung steps dan konversi ke integer
steps = int(np.ceil(nb_samples / batch_size))

# Lakukan prediksi
predict = best_model.predict(test_generator, steps=steps)

# Ambil kelas prediksi
predicted_classes = np.argmax(predict, axis=1)
class_names = ['cat', 'dog']  # Sesuaikan dengan label Anda
predicted_labels = [class_names[i] for i in predicted_classes]

# Tampilkan hasil
print("Predicted labels for first 10 samples:", predicted_labels[:10])

# here "category" column store the index of higher predicted value
test_df['category'] = np.argmax(predict, axis=-1)

# here predicted value will replace by "cat" for 0 & "dog" for 1
label_map = dict((v,k) for k,v in train_generator.class_indices.items())
test_df['category'] = test_df['category'].replace(label_map)

# See predicted dataframe
test_df.head()

"""## **7.1. Visualize Result**"""

# see how many images classify into which class
test_df['category'].value_counts().plot.bar()

"""## **7.2. See Predicted Image With Images**"""

sample_test = test_df.head(18)
sample_test.head()
plt.figure(figsize=(12, 24))
for index, row in sample_test.iterrows():
    filename = row['filename']
    category = row['category']
    img = load_img("/content/sample_data/test1/"+filename, target_size=IMAGE_SIZE)
    plt.subplot(6, 3, index+1)
    plt.imshow(img)
    plt.xlabel(filename + '(' + "{}".format(category.upper()) + ')' )
plt.tight_layout()
plt.show()

"""If you get any issues during run this notebook.Feel free to contact.
[Linkedin](https://www.linkedin.com/in/sidharth178),
[Github](https://github.com/sidharth178)

Thank You.

"""



